# 三维决策系统后端开发指南

## 📋 前端实现检查清单

### ✅ 已实现的前端功能

1. **温度设置** ✅
   - 位置：`src/services/LLMService.ts` - `getCustomInterpretation()` 方法
   - 实现：默认温度 0.75（0.7-0.8之间）
   - 调用：`TripleAnalysisGenerator.generateVerdict()` 明确传入 0.75

2. **征兆系统展示** ✅
   - 位置：`src/features/cross-system/views/TripleAnalysisPage.vue`
   - 实现：完整的征兆展示组件（顺境之象/阻滞之象）
   - 样式：衬线体 + 行高1.8+，营造书信感

3. **Prompt构建** ✅
   - 位置：`src/features/cross-system/services/TripleAnalysisGenerator.ts`
   - 实现：完整的Prompt构建逻辑，包含征兆系统要求

4. **数据结构** ✅
   - 位置：`src/features/cross-system/services/TripleAnalysisGenerator.ts`
   - 实现：`VerdictResult` 接口包含 `signs` 字段

### ⚠️ 需要后端支持的功能

1. **LLM API调用**
   - 端点：`POST /api/llm/chat`
   - 需要支持温度参数（0.7-0.8）
   - 需要支持自定义Prompt

2. **响应格式解析**
   - 需要返回JSON格式的裁决结果
   - 必须包含 `signs` 字段（顺境之象/阻滞之象）

---

## 🎯 后端开发提示词

### 1. API端点规范

**端点**：`POST /api/llm/chat`

**请求格式**：
```json
{
  "prompt": "用户提示词（完整的三维决策Prompt）",
  "systemPrompt": "系统提示词（可选）",
  "model": "deepseek-chat",
  "provider": "deepseek",
  "temperature": 0.75,
  "maxTokens": 4000
}
```

**关键参数说明**：
- `temperature`: **必须设置为 0.75**（0.7-0.8之间）
  - 理由：v4.0强调"文采"和"比喻"，温度太低会太干巴，太高会胡言乱语
- `maxTokens`: 建议 4000（三维决策需要较长的输出）
- `prompt`: 前端会传入完整的Prompt，包含所有上下文信息

**响应格式**：
```json
{
  "success": true,
  "data": {
    "content": "AI返回的完整文本（JSON格式的裁决结果）"
  }
}
```

---

### 2. System Prompt（后端LLM调用）

**⚠️ 重要**：前端会构建完整的Prompt，但后端需要确保LLM理解以下核心要求：

#### 2.1 角色定位
```
你是精通紫微、易经、塔罗的"天机谋士"（Strategist of Destiny）。
你的职责是：基于三维数据，通过"取象比类"的方法，为用户揭示当下的能量结构，并提供战略层面的"定调"。
```

#### 2.2 绝对红线（Constraints）
1. **禁止**使用任何商业KPI术语（如：转化率、ROI、成本占比、阈值、百分比）
2. **禁止**布置具体的执行任务（如：做Excel、发邮件、开会、写合同）
3. **禁止**编造迷信的巧合（如：出门摔跤、看见乌鸦、杯子碎了）
4. **禁止**绝对化的预言（如：你一定会在下周二成功）
5. **禁止**预测具体数据（如：面试通过率、转化率、成本超支百分比）

#### 2.3 输出格式要求

**必须返回JSON格式**，包含以下字段：

```json
{
  "verdict": "Yes/No/Wait",
  "verdict_title": "四字判词（如：潜龙勿用、借风使船、庸人自扰）",
  "dimensions": {
    "ziwei": {
      "score": 85,
      "tag": "格局强旺",
      "insight": "你有统帅千军的能力，却被困在只会冲锋的岗位上。"
    },
    "yijing": {
      "score": 40,
      "tag": "明夷之局",
      "insight": "此乃'明夷'之局，光芒需内敛，强出头必遭枪打。"
    },
    "tarot": {
      "score": 30,
      "tag": "恐惧失败",
      "insight": "你的潜意识在尖叫着'逃跑'，哪怕你嘴上说很想做。"
    }
  },
  "analysis": {
    "root_cause": "此乃'心比天高，命比纸薄'的暂时性困局。你的能力（紫微）溢出了，但环境（易经）接不住你。",
    "blind_spot": "你以为只要努力就能改变环境，但其实你是在用战术上的勤奋掩盖战略上的焦虑。",
    "final_advice": "'忍'。现在的'忍'不是认怂，而是为了三个月后更好的'爆发'。"
  },
  "signs": {
    "flow": [
      "关键人破冰：原本一直推诿或回复冷淡的关键人物，突然主动释放善意，或在一个非正式场合与你建立了私交。",
      "流程简化：你发现原本复杂的流程突然被简化，或者有人主动为你补齐了缺失的信息拼图。"
    ],
    "friction": [
      "无效循环：你发现团队在同一个非核心细节上反复争执，或者流程审批莫名卡在某个非关键节点。这是'蹇卦'（跛足难行）的典型投射。",
      "沟通错位：当你感到无论如何解释，对方都似乎听不懂你的核心诉求，沟通充满了'错位感'。"
    ]
  },
  "action_roadmap": [
    {
      "timeline": "短期（本月内）",
      "action": "深入调研适合的领域（文化、疗愈、休闲）",
      "tips": "不要注册公司，不要投入资金，只做市场调研和可行性报告"
    }
  ]
}
```

---

### 3. 征兆系统要求（Critical）

#### 3.1 核心原则
- **我们不预测数据，我们预测"现象"（应象）**
- 通过描述"体感"和"氛围"，让用户产生"对！就是这种感觉！"的直觉验证
- **必须强调画面感**，避免通用废话

#### 3.2 顺境之象（Signs of Flow）- 2-3条

**要求**：描述一种"阻力消失"或"意外巧合"的场景，必须带有**画面感**和**体感**

**❌ 错误示例（通用废话）**：
- "沟通不顺"
- "你会感到不开心"
- "事情会进展顺利"

**✅ 正确示例（画面感）**：
- "关键人破冰：原本一直推诿或回复冷淡的关键人物，突然主动释放善意，或在一个非正式场合与你建立了私交。"
- "流程简化：你发现原本复杂的流程突然被简化，或者有人主动为你补齐了缺失的信息拼图。"
- "你不得不反复解释同一个简单的概念，而对方眼神游离。"（要这种带体感的描写）

#### 3.3 阻滞之象（Signs of Friction）- 2-3条

**要求**：描述一种"推不动"或"鬼打墙"的心理/人际状态，必须带有**画面感**和**体感**

**❌ 错误示例（加戏）**：
- "你会丢钱包或者电脑死机"
- "出门会摔跤"

**✅ 正确示例（画面感）**：
- "无效循环：你发现团队在同一个非核心细节上反复争执超过三次，或者流程审批莫名卡在某个非关键节点。这是'蹇卦'（跛足难行）的典型投射。"
- "沟通错位：当你感到无论如何解释，对方都似乎听不懂你的核心诉求，沟通充满了'错位感'。"
- "泥潭状态：你会感到无论投入多少精力，事情总是偏离预期，像是在泥潭中奔跑，越用力越陷越深。"

---

### 4. 温度设置（Critical）

**必须设置**：`temperature: 0.75`（0.7-0.8之间）

**理由**：
- v4.0强调"文采"和"比喻"（如"孤掌难鸣"、"锦衣夜行"）
- 如果温度太低（如0.2），AI说话会太干巴，像说明书
- 如果太高（>1.0），容易胡言乱语

**实现建议**：
```javascript
// 后端代码示例
const requestBody = {
  model: "deepseek-chat",
  messages: [
    { role: "system", content: systemPrompt },
    { role: "user", content: userPrompt }
  ],
  temperature: 0.75, // 🎯 开发红线：必须0.7-0.8
  max_tokens: 4000
};
```

---

### 5. 错误处理

**如果LLM返回格式错误**：
- 前端会尝试解析JSON
- 如果解析失败，前端会抛出错误："天机晦涩，请重试（不扣币）"
- 后端应该确保返回的文本包含有效的JSON

**如果LLM返回空内容**：
- 前端会检测空响应
- 抛出错误："天机晦涩，请重试（不扣币）"
- 后端应该确保至少返回一些内容

---

### 6. 测试建议

#### 6.1 测试温度设置
- 测试 temperature = 0.7：应该有一定文采，但不过度
- 测试 temperature = 0.75：**推荐值**，文采和准确性平衡
- 测试 temperature = 0.8：文采更丰富，但需要确保不胡言乱语

#### 6.2 测试征兆生成
- 检查是否生成2-3条顺境之象
- 检查是否生成2-3条阻滞之象
- 检查是否有画面感（避免通用废话）
- 检查是否避免迷信巧合（如"出门摔跤"）

#### 6.3 测试JSON格式
- 确保返回的文本包含有效的JSON
- 确保所有必需字段都存在
- 确保 `signs.flow` 和 `signs.friction` 都是数组

---

### 7. 前端调用示例

前端会这样调用后端API：

```typescript
// 前端代码（已实现）
const response = await LLMService.getCustomInterpretation(prompt, 0.75);

// 后端应该接收到的请求
POST /api/llm/chat
{
  "prompt": "完整的Prompt文本...",
  "temperature": 0.75,
  "maxTokens": 4000
}
```

---

## 📝 总结

### 后端必须实现的功能

1. ✅ **温度参数支持**：必须支持 0.7-0.8 的温度设置（推荐0.75）
2. ✅ **JSON格式响应**：确保返回的文本包含有效的JSON
3. ✅ **征兆系统支持**：确保 `signs` 字段包含 `flow` 和 `friction` 数组
4. ✅ **画面感要求**：在Prompt中强调画面感，避免通用废话

### 前端已实现的功能

1. ✅ Prompt构建（包含所有要求）
2. ✅ 温度设置（0.75）
3. ✅ 征兆展示（UI组件）
4. ✅ 衬线体样式（书信感）
5. ✅ 数据结构定义（VerdictResult接口）

### 开发红线（必须遵守）

1. **温度**：0.7-0.8（推荐0.75）
2. **征兆画面感**：必须强调画面感，避免通用废话
3. **UI氛围感**：前端已实现衬线体+行高1.8+，后端只需确保返回正确格式

---

## 🔗 相关文件

- 前端Prompt构建：`src/features/cross-system/services/TripleAnalysisGenerator.ts`
- 前端展示组件：`src/features/cross-system/views/TripleAnalysisPage.vue`
- LLM服务调用：`src/services/LLMService.ts`
- 产品文档：`docs/三维决策优化方案第三版.md`
